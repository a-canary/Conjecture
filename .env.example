# Environment Variables Template
# Copy this file to .env and fill in your actual API keys

# LLM API Keys
# Primary: Chutes.ai (default provider)
Conjecture_LLM_API_KEY=your_chutes_api_key_here
CHUTES_API_KEY=your_chutes_api_key_here

# Backup providers (optional)
GEMINI_API_KEY=your_gemini_api_key_here
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Database Configuration
Conjecture_DB_PATH=data/conjecture.db
Conjecture_DB_TYPE=sqlite

# Model Configuration - Default to Chutes.ai
Conjecture_EMBEDDING_MODEL=all-MiniLM-L6-v2
Conjecture_LLM_MODEL=zai-org/GLM-4.6-turbo
Conjecture_LLM_PROVIDER=chutes
Conjecture_LLM_API_URL=https://llm.chutes.ai/v1

# Performance Settings
Conjecture_CONFIDENCE=0.7
Conjecture_MAX_CONTEXT=4000
Conjecture_BATCH_SIZE=10

# Debug Settings
Conjecture_DEBUG=false

# Optional: Other API Keys
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here