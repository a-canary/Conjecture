# ===========================================
# CONJECTURE CLI PROVIDER CONFIGURATION
# ===========================================
# Copy this file to .env and configure your preferred providers
# Format: PROVIDER_API_URL, PROVIDER_API_KEY, PROVIDER_MODEL
# Only ONE provider should be uncommented at a time

# ===========================================
# LOCAL PROVIDERS (Priority 1-2) - RECOMMENDED FOR PRIVACY
# ===========================================

# Ollama - Local LLM Server (Priority 1)
# Install: https://ollama.ai/ | Start: ollama serve | Pull: ollama pull llama2
#PROVIDER_API_URL=http://localhost:11434
#PROVIDER_API_KEY=
#PROVIDER_MODEL=llama2 # one of [llama2, mistral, codellama]

# LM Studio - Local GUI LLM Server (Priority 2)
# Install: https://lmstudio.ai/ | Start: Launch LM Studio app | Load model in UI
# For ibm/granite-4-h-tiny model: PROVIDER_MODEL=ibm/granite-4-h-tiny
# NOTE: Do not include /v1 in the URL as the client adds it automatically
#PROVIDER_API_URL=http://localhost:1234
#PROVIDER_API_KEY=
#PROVIDER_MODEL=ibm/granite-4-h-tiny # one of [ibm/granite-4-h-tiny, microsoft/DialoGPT-medium, etc.]

# ===========================================
# CLOUD PROVIDERS (Priority 3-8) - FAST SETUP
# ===========================================

# Chutes.ai (Priority 3)
# Get key: https://chutes.ai/ | Features: Fast, cost-effective, reliable
PROVIDER_API_URL=https://llm.chutes.ai/v1
PROVIDER_API_KEY=cpk_your-api-key-here
PROVIDER_MODEL=zai-org/GLM-4.6-FP8 # one of [openai/gpt-oss-20b, zai-org/GLM-4.5-Air, zai-org/GLM-4.6-FP8]

# OpenRouter (Priority 4)
# Get key: https://openrouter.ai/keys | Features: 100+ models, competitive pricing
#PROVIDER_API_URL=https://openrouter.ai/api/v1
#PROVIDER_API_KEY=sk-or-your-api-key-here
#PROVIDER_MODEL=openai/gpt-3.5-turbo # one of [openai/gpt-3.5-turbo, openai/gpt-4, anthropic/claude-3-haiku]

# Groq (Priority 5)
# Get key: https://console.groq.com/keys | Features: Lightning fast responses
#PROVIDER_API_URL=https://api.groq.com/openai/v1
#PROVIDER_API_KEY=gsk_your-api-key-here
#PROVIDER_MODEL=llama3-8b-8192 # one of [llama3-8b-8192, llama3-70b-8192, mixtral-8x7b-32768]

# OpenAI (Priority 6)
# Get key: https://platform.openai.com/api-keys | Features: Most popular, reliable
#PROVIDER_API_URL=https://api.openai.com/v1
#PROVIDER_API_KEY=sk-your-api-key-here
#PROVIDER_MODEL=gpt-3.5-turbo # one of [gpt-3.5-turbo, gpt-4, gpt-4-turbo]

# Anthropic (Priority 7)
# Get key: https://console.anthropic.com/ | Features: Advanced reasoning models
#PROVIDER_API_URL=https://api.anthropic.com
#PROVIDER_API_KEY=sk-ant-your-api-key-here
#PROVIDER_MODEL=claude-3-haiku-20240307 # one of [claude-3-haiku-20240307, claude-3-sonnet-20240229]

# Google (Priority 8)
# Get key: https://makersuite.google.com/app/apikey | Features: Google's latest models
#PROVIDER_API_URL=https://generativelanguage.googleapis.com
#PROVIDER_API_KEY=your-google-api-key-here
#PROVIDER_MODEL=gemini-pro # one of [gemini-pro, gemini-pro-vision]

# Cohere (Priority 9)
# Get key: https://dashboard.cohere.ai/api-keys | Features: Enterprise-grade models
#PROVIDER_API_URL=https://api.cohere.ai/v1
#PROVIDER_API_KEY=your-cohere-api-key-here
#PROVIDER_MODEL=command # one of [command, command-light, command-nightly]

# ===========================================
# ADDITIONAL SETTINGS
# ===========================================

# Embedding model for semantic search
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Database path
DB_PATH=data/conjecture.db

# ===========================================
# QUICK START INSTRUCTIONS
# ===========================================
# 1. Choose ONE provider from above
# 2. Uncomment the PROVIDER_* lines for your chosen provider
# 3. Replace placeholder API key with your actual key (if needed)
# 4. Choose your model from the available options
# 5. Save this file
# 6. Run: python simple_conjecture_cli.py validate
#
# NOTE: Only ONE provider should be active at a time
#       Local providers don't need API keys
#       Chutes.ai is pre-configured with working credentials