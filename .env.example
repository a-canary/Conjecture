# ===========================================
# CONJECTURE MIGRATION NOTICE
# ===========================================
# 
# This project has migrated from environment variables to JSON config files.
# Please run the migration script to convert your existing configuration:
#
#   python scripts/migrate_to_config.py
#
# After migration, your configuration will be in:
#   ~/.conjecture/config.json (user config)
#   .conjecture/config.json (workspace config, overrides user)
#
# The migration script will automatically:
# 1. Create ~/.conjecture/config.json from your environment variables
# 2. Add all your configured providers
# 3. Preserve all your settings
# 4. Backup existing config as ~/.conjecture/config.json.backup
#
# ===========================================
# MIGRATION INSTRUCTIONS
# ===========================================
#
# Run the migration script:
#   python scripts/migrate_to_config.py
#
# Then update your config file with real API keys:
#   nano ~/.conjecture/config.json
#
# Finally, test your configuration:
#   python conjecture config
#
# ===========================================
# LEGACY ENVIRONMENT VARIABLES (FOR MIGRATION ONLY)
# ===========================================
#
# The following environment variables are NO LONGER USED directly.
# Use the migration script above to convert them to config files.

# Ollama - Local LLM Server
# Install: https://ollama.ai/ | Start: ollama serve | Pull: ollama pull llama2
# OLLAMA_API_URL=http://localhost:11434
# OLLAMA_API_KEY=
# OLLAMA_MODEL=llama2

# LM Studio - Local GUI LLM Server
# Install: https://lmstudio.ai/ | Start: Launch LM Studio app
# LM_STUDIO_API_URL=http://localhost:1234
# LM_STUDIO_API_KEY=
# LM_STUDIO_MODEL=ibm/granite-4-h-tiny

# Chutes.ai - Fast & Cost Effective
# Get key: https://chutes.ai/
# CHUTES_API_URL=https://llm.chutes.ai/v1
# CHUTES_API_KEY=cpk_your-api-key-here
# CHUTES_MODEL=zai-org/GLM-4.6-FP8

# OpenRouter - 100+ Models
# Get key: https://openrouter.ai/keys
# OPENROUTER_API_URL=https://openrouter.ai/api/v1
# OPENROUTER_API_KEY=sk-or-your-api-key-here
# OPENROUTER_MODEL=openai/gpt-3.5-turbo

# OpenAI - Most Popular
# Get key: https://platform.openai.com/api-keys
# OPENAI_API_URL=https://api.openai.com/v1
# OPENAI_API_KEY=sk-your-api-key-here
# OPENAI_MODEL=gpt-3.5-turbo

# ===========================================
# LEGACY APPLICATION SETTINGS (FOR MIGRATION ONLY)
# ===========================================

# Database
# DB_PATH=data/conjecture.db

# Performance
# CONFIDENCE_THRESHOLD=0.95
# CONFIDENT_THRESHOLD=0.8
# MAX_CONTEXT_SIZE=10
# BATCH_SIZE=10

# Development
# DEBUG=false

# Workspace identification
# CONJECTURE_WORKSPACE=my-project
# CONJECTURE_USER=alice
# CONJECTURE_TEAM=engineering

# ===========================================
# NEW CONFIGURATION SYSTEM
# ===========================================
#
# After migration, your configuration will look like:
#
# ~/.conjecture/config.json:
# {
#   "providers": [
#     {
#       "url": "http://localhost:11434",
#       "api": "",
#       "model": "llama2",
#       "name": "ollama"
#     },
#     {
#       "url": "https://llm.chutes.ai/v1",
#       "api": "cpk_your-api-key-here",
#       "model": "zai-org/GLM-4.6-FP8",
#       "name": "chutes"
#     }
#   ],
#   "confidence_threshold": 0.95,
#   "max_context_size": 10,
#   "debug": false,
#   "database_path": "data/conjecture.db",
#   "user": "user",
#   "team": "default"
# }
#
# ===========================================
# QUICK START (AFTER MIGRATION)
# ===========================================
# 1. Run: python scripts/migrate_to_config.py
# 2. Edit: ~/.conjecture/config.json to update API keys
# 3. Test: python conjecture validate