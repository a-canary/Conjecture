---
archived: 2024-10-30
reason: Content consolidated into new unified documentation
consolidated_into: SystemArchitecture.md
migration_status: complete
quality_note: Replaced by higher-quality unified documentation
---

# Evidence Structure - Claims Architecture

## Executive Summary

Evidence Structure redefines AI knowledge management by embracing uncertainty through claims with confidence scoring. By treating information as claims rather than absolute facts, the system enables nuanced reasoning where confidence weights drive decision-making, providing reliable intelligence that acknowledges sources and maintains traceability.

## Core Philosophy

### Claims Over Facts

Traditional AI systems store knowledge as absolute truths, creating fragile foundations when new evidence emerges. Conjecture stores information as claims with inherent uncertainty, where confidence scores reflect source quality and validation methodology.

```
Traditional: "Customer churn rate is 23%"
Claims-Based: <claim id="c142" confidence="0.90" source_ref="s89">Customer churn rate is 23% based on Q3 2024 data</claim>
```

### Confidence-Weighted Reasoning

All claims inherit confidence based on systematic evaluation of source methodology, enabling the system to weigh information appropriately and maintain transparency about knowledge quality.

## Claim Architecture

### Claim Structure

Every claim follows a standardized structure that enables precise tracking and reference:

```
<claim id="c[unique]" confidence="[0.0-1.0]" source_ref="s[unique]">Claim content here</claim>
```

**Components:**
- **ID**: Unique identifier for precise tool targeting and cross-reference
- **Confidence**: Quality score based on source validation methodology
- **Source Reference**: Short identifier linking to detailed source information
- **Content**: The actual claim being made

### Confidence Scoring Tiers

Source quality determines initial confidence scores:

```
Primary (0.95): Direct validation using scientific method, peer-reviewed research
Validated (0.85): External references with citations, no observed fallacies
Credible (0.70): Reputable sources with supporting evidence
Unverified (0.30): Claims without supporting evidence or citations
Assumptions (0.10-0.20): Common beliefs or hypotheses for investigation
```

### Source Reference System

Short source identifiers avoid long paths in prompts while maintaining traceability:

```
Source Reference Format: s89 (database index to full source details)

Tool Reference Example:
<tool name="read_sources" claim="c142">Retrieve detailed explanation of methodology</tool>
```

## Claim Lifecycle Management

### Ingestion Process

1. **Claim Generation**: LLM generates claim with confidence assessment
2. **Embedding Creation**: Semantic vector generated for similarity matching
3. **Deduplication Check**: Search existing claims with cosine-similarity > 0.95
4. **Quality Assessment**: Validate claim structure and confidence scoring
5. **Storage**: Add to claim database with full metadata

### Deduplication Algorithm

```
Input Claim → Generate Embedding → Search Similar Claims
├─ No Match (>0.95) → Create New Claim Entry
└─ Match Found → Compare Confidence → Keep Higher Score
    └─ Merge Source References → Update Metadata
```

### Claim Evolution

Claims maintain their original confidence scores while accumulating additional evidence:
- **No Confidence Decay**: Preserves niche claims from being marginalized
- **Evidence Accumulation**: Multiple claims strengthen confidence in conclusions
- **Source Attribution**: All conclusions trace to original claim sources

## Quality Management

### Group-Think Bias Prevention

Popular beliefs receive no automatic confidence elevation:
- **Individual Assessment**: Each claim judged on source methodology
- **Contrarian Support**: Unpopular claims with solid sources retain high confidence
- **Investigation Encouragement**: Common assumptions labeled as assumptions (0.10-0.20) for validation

### Source Validation

Confidence scoring emphasizes systematic validation over popularity:
- **Methodology Focus**: Scientific method, logical proof, peer review
- **Evidence Requirements**: Citations, reproducibility, data availability
- **Fallacy Detection**: Logical analysis for reasoning errors

### Conflict Resolution

When contradictory claims exist:
- **Confidence Comparison**: Higher confidence claims take precedence
- **Source Comparison**: Better methodology sources preferred
- **Contextual Relevance**: Claim applied based on specific query context

## Integration Points

### Tool Response Integration

Tool responses generate new claims through structured processing:
- **Streaming Processing**: Large responses processed in chunks
- **Claim Extraction**: Key insights preserved as new claims
- **Confidence Assignment**: Claims inherit confidence from tool sources

### Query Resolution Support

Claims enable automatic query resolution:
- **Similarity Matching**: High confidence claims automatically resolve matching queries
- **Evidence Accumulation**: Multiple claims provide comprehensive answers
- **Confidence Thresholds**: Resolution requires minimum confidence levels

### Cross-Reference System

Claims maintain relationships across the system:
- **Query References**: Claims linked to generating queries
- **Tool References**: Claims generated from specific tool executions
- **Resolution References**: Claims incorporated into resolution statements

## Performance Optimization

### Embedding Optimization

- **Caching Strategy**: Frequent claim embeddings cached for instant access
- **Similarity Indexing**: Pre-computed similarity relationships for fast matching
- **Batch Processing**: Multiple claim updates processed efficiently

### Storage Optimization

- **Lazy Loading**: Claim details loaded only when required
- **Compression**: Claim metadata compressed for efficient storage
- **Index Management**: Optimized indexes for confidence and source queries

### Query Performance

- **Candidate Over-Fetching**: Retrieve 200+ candidates, filter by quality
- **Composite Scoring**: Balance similarity, confidence, and recency
- **Relevance Optimization**: Prioritize recent, high-confidence claims

## Security Considerations

### Claim Integrity

- **Immutable History**: Claim evolution tracked with complete audit trail
- **Source Verification**: Source references validated before confidence assignment
- **Modification Controls**: Claim updates only through systematic processes

### Access Management

- **Read Permissions**: Controlled access to sensitive claim sources
- **Write Permissions**: Restricted claim modification capabilities
- **Audit Logging**: Complete tracking of claim lifecycle operations

## Success Metrics

Evidence Structure performance measured through:

- **Claim Accuracy**: Percentage of high-confidence claims validated over time
- **Source Quality Distribution**: Concentration of claims in higher confidence tiers
- **Deduplication Efficiency**: Percentage of duplicate claims successfully detected
- **Query Resolution Rate**: Claims successfully resolving query requests
- **Confidence Consistency**: Reliability of confidence scoring across sources

Evidence Structure provides the foundation for reliable AI intelligence by embracing uncertainty through systematic confidence management, enabling nuanced reasoning that acknowledges knowledge quality while maintaining complete traceability and transparency.
