# ===========================================
# CONJECTURE RESEARCH ENVIRONMENT
# ===========================================
# This file contains research-specific environment variables
# These override the main project .env settings

# ===========================================
# RESEARCH PROVIDER CONFIGURATION
# ===========================================

# Primary provider for research experiments
PROVIDER_API_URL=https://llm.chutes.ai/v1
PROVIDER_API_KEY=your_chutes_api_key_here
PROVIDER_MODEL=zai-org/GLM-4.6-FP8

# Individual provider settings (override PROVIDER_* above)
CHUTES_API_KEY=your_chutes_api_key_here
OPENROUTER_API_KEY=your_openrouter_api_key_here  
OPENAI_API_KEY=your_openai_api_key_here

# Local providers (for comparison experiments)
OLLAMA_API_URL=http://localhost:11434
OLLAMA_MODEL=llama2
LM_STUDIO_API_URL=http://localhost:1234
LM_STUDIO_MODEL=ibm/granite-4-h-tiny

# ===========================================
# RESEARCH EXPERIMENT SETTINGS
# ===========================================

# Judge model for LLM-based evaluation
JUDGE_MODEL=chutes:zai-org/GLM-4.6-FP8
JUDGE_PROVIDER=chutes
JUDGE_TEMPERATURE=0.1
JUDGE_MAX_TOKENS=1000

# Experiment flags
HYPOTHESIS_VALIDATION=true
MODEL_COMPARISON=true
BASELINE_COMPARISON=true
GENERATE_TEST_CASES=true

# Output settings
SAVE_RESULTS=true
GENERATE_VISUALIZATIONS=true
CREATE_REPORTS=true

# ===========================================
# WORKSPACE CONTEXT
# ===========================================

CONJECTURE_WORKSPACE=conjecture-research
CONJECTURE_USER=researcher
CONJECTURE_TEAM=ai-lab

# ===========================================
# DATABASE AND PERFORMANCE
# ===========================================

DB_PATH=research/data/conjecture_research.db
CONFIDENCE_THRESHOLD=0.95
MAX_CONTEXT_SIZE=20
BATCH_SIZE=5
DEBUG=true